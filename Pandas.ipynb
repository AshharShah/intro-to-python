{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is the most popular Python library for data analysis.\n",
        "\n",
        "The first step that we need to do, when we start working with pandas is to import its library.\n",
        "\n"
      ],
      "metadata": {
        "id": "ECJ8uF1kxq8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "vD3XQW9expAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating data**\n",
        "There are two core objects in pandas: the DataFrame and the Series.\n",
        "\n",
        "DataFrame\n",
        "A DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row and a column.\n",
        "\n",
        "For example, consider the following simple DataFrame"
      ],
      "metadata": {
        "id": "pb313DC4xhvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Morning': [8, 11], 'Evening': [16, 18]})"
      ],
      "metadata": {
        "id": "vlQmGH1n0NaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly it can have string in it's entries as well"
      ],
      "metadata": {
        "id": "i8jZKbhREBDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'michael': ['It was fun.', 'It was boring.'], 'James': ['Pretty good.', 'Bland.']})"
      ],
      "metadata": {
        "id": "WmK19LQ4EH6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also set the titles to the rows in the dataframe"
      ],
      "metadata": {
        "id": "a77xOiyoFMMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'michael': ['It was fun.', 'It was boring.'], 'James': ['Pretty good.', 'Bland.']}, index=['Product A', 'Product B'])"
      ],
      "metadata": {
        "id": "Sl0e8KX30Q_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading data files**\n",
        "Being able to create a DataFrame. But, most of the time, we won't actually be creating our own data by hand and we'll be working on a data that already exists.\n",
        "\n",
        "Data can be stored in any of a number of different forms and formats. By far the most basic of these is a CSV file. When you open a CSV file, you get something that looks like this:"
      ],
      "metadata": {
        "id": "o_QEnoI1GEt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Product A,Product B,Product C,\n",
        "30,21,9,\n",
        "35,34,1,\n",
        "41,11,11"
      ],
      "metadata": {
        "id": "4tWvegW6GJLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So a CSV file is a table of values separated by commas. Which give it the name: \"Comma-Separated Values\", or CSV.\n",
        "\n",
        "Let's now see what a real dataset looks like when we read it into a DataFrame. We'll use the pd.read_csv() function to read the data into a DataFrame. This goes thusly:"
      ],
      "metadata": {
        "id": "zYVq6x6YGU6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record = pd.read_csv(\"/ds_salaries.csv\")"
      ],
      "metadata": {
        "id": "SyH_QCXuGUNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To print the dataset, just type the name of the Dataframe, it will return the first 5 and the last 5 rows"
      ],
      "metadata": {
        "id": "SF74Pkjrg3wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record"
      ],
      "metadata": {
        "id": "_POiqcfrhDG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the shape attribute to check how large the resulting DataFrame is:"
      ],
      "metadata": {
        "id": "tvPHCdd1LpDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.shape"
      ],
      "metadata": {
        "id": "jH1vUNWNLoVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our new DataFrame has 607 records split across 12 different columns. That's more than 7 thousand entries!\n",
        "\n",
        "We can examine the contents of the resultant DataFrame using the head() command, which grabs the first five rows:"
      ],
      "metadata": {
        "id": "RfPm-QLgL2Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.head()"
      ],
      "metadata": {
        "id": "S-EsNyCgL1au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likewise, we can get the last five rows using the **tail()** command.\n",
        "\n",
        "You might have noticed we have 2 column acting as the index, we can set a column as the index column manually using **index_col** command"
      ],
      "metadata": {
        "id": "wFr902iLMRwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record = pd.read_csv(\"/content/ds_salaries.csv\", index_col=0)\n",
        "salary_record.head()"
      ],
      "metadata": {
        "id": "Hi5gaC0N0fOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Indexing, Selecting & Assigning**\n",
        "Selecting specific values of a pandas DataFram is a step you'll require in almost every oper, so one of the first things you need to learn in working with data in Python is how to select required the data points quickly and effectively."
      ],
      "metadata": {
        "id": "qBWbpZMXgARr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record"
      ],
      "metadata": {
        "id": "FupkhMZ50fjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Native accessors**\n",
        "Native Python objects provide good ways of indexing data. Pandas carries all of these over, which helps make it easy to start with.\n",
        "\n",
        "In Python, we can access the property of an object by accessing it as an attribute. A **book** object, for example, might have a **title** property, which we can access by calling **book.title**. Columns in a pandas DataFrame work in much the same way.\n",
        "\n",
        "Hence to access the **job_title** property of **salary_record** we can use:"
      ],
      "metadata": {
        "id": "c-eR86WRhO4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.job_title"
      ],
      "metadata": {
        "id": "zM7ewNzFiOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have a Python dictionary, we can access its values using the indexing **[ ]** operator. We can do the same with columns in a DataFrame:"
      ],
      "metadata": {
        "id": "ifNvc3PvicO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record['job_title']"
      ],
      "metadata": {
        "id": "MQSdwKPVirK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have special characters in the column name, we wont we able access them through **Dataframe.column** method, this is where **Dataframe[ ]** method has advantage over the previous method.\n",
        "\n",
        "To access a specific entry, add another **[ ]** (with the index number of the row in it) next to the column name, as shown below:"
      ],
      "metadata": {
        "id": "w_iu0K0ujJTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record['job_title'][0]"
      ],
      "metadata": {
        "id": "mnPUEVy-mHdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Indexing in pandas**\n",
        "The indexing operator and attribute selection are nice because they work just like they do in the rest of the Python ecosystem. As a beginner, this makes them easy to pick up and use. However, pandas has its own accessor operators, loc and iloc. For more advanced operations, these are the ones you're supposed to be using.\n",
        "\n",
        "### **Index-based selection**\n",
        "Pandas indexing works in one of two paradigms. The first is index-based selection: selecting data based on its numerical position in the data. iloc follows this paradigm.\n",
        "\n",
        "To select the first row of data in a DataFrame, we may use the following:"
      ],
      "metadata": {
        "id": "1LllPLsonz57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.iloc[0]"
      ],
      "metadata": {
        "id": "QlEhAuDjoScG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both loc and iloc are row-first, column-second. This is the opposite of what we do in native Python, which is column-first, row-second.\n",
        "\n",
        "This means that it's marginally easier to retrieve rows, and marginally harder to get retrieve columns. To get a column with iloc, we can do the following:"
      ],
      "metadata": {
        "id": "lDBe9ceMp5FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.iloc[:, 4]"
      ],
      "metadata": {
        "id": "RDBSWWpWp6hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On its own, the : operator, which also comes from native Python, means \"everything\". When combined with other selectors, however, it can be used to indicate a range of values. For example, to select the **salary** column from just the first, second, and third row, we would do:"
      ],
      "metadata": {
        "id": "E3VtLC-FqRP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.iloc[:3, 4]"
      ],
      "metadata": {
        "id": "YwJOFPvMqZoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or, to select just the second and third entries, we would do:"
      ],
      "metadata": {
        "id": "2kSuCwViq1Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.iloc[1:3, 4]"
      ],
      "metadata": {
        "id": "knR0RE-Dq2Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Label-based selection**\n",
        "The second paradigm for attribute selection is the one followed by the loc operator: label-based selection. In this paradigm, it's the data index value, not its position, which matters.\n",
        "\n",
        "For example, to get the first entry in **salary** column in **salary_record**, we would now do the following:"
      ],
      "metadata": {
        "id": "CRjC-twCrRPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.loc[0]['salary']"
      ],
      "metadata": {
        "id": "nwr9afXfrg1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Choosing between loc and iloc**\n",
        "When choosing or transitioning between loc and iloc, there is one \"gotcha\" worth keeping in mind, which is that the two methods use slightly different indexing schemes.\n",
        "\n",
        "iloc uses the Python stdlib indexing scheme, where the first element of the range is included and the last one excluded. So 0:10 will select entries 0,...,9. loc, meanwhile, indexes inclusively. So 0:10 will select entries 0,...,10.\n",
        "\n",
        "Why the change? Remember that loc can index any stdlib type: strings, for example. If we have a DataFrame with index values Apples, ..., Potatoes, ..., and we want to select \"all the alphabetical fruit choices between Apples and Potatoes\", then it's a lot more convenient to index df.loc['Apples':'Potatoes'] than it is to index something like df.loc['Apples', 'Potatoet'] (t coming after s in the alphabet).\n",
        "\n",
        "This is particularly confusing when the DataFrame index is a simple numerical list, e.g. 0,...,1000. In this case df.iloc[0:1000] will return 1000 entries, while df.loc[0:1000] return 1001 of them! To get 1000 elements using loc, you will need to go one lower and ask for df.loc[0:999].\n",
        "\n",
        "Otherwise, the semantics of using loc are the same as those for iloc."
      ],
      "metadata": {
        "id": "WAibxQ1MsAXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conditional selection**\n",
        "So far we've been indexing various strides of data, using structural properties of the DataFrame itself. To do interesting things with the data, however, we often need to ask questions based on conditions.\n",
        "\n",
        "For example, suppose that we're interested specifically in better-than-average salaries of the data scientist.\n",
        "\n",
        "Suppose we want all the employees living in US, we can use the following:"
      ],
      "metadata": {
        "id": "YpU_MW82tJR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.loc[salary_record.employee_residence ==\"US\"]"
      ],
      "metadata": {
        "id": "HYpetvZ7sHKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we want to add another condition (people with exexutive level expreience), we can do that using the **&** symbol, as we've done below:"
      ],
      "metadata": {
        "id": "pE6u2dLhwomW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.loc[(salary_record.employee_residence ==\"US\") & (salary_record.experience_level==\"EX\")]"
      ],
      "metadata": {
        "id": "g2-_eRwOwuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assigning data**\n",
        "Going the other way, assigning data to a DataFrame is easy. You can assign either a constant value:"
      ],
      "metadata": {
        "id": "Ez7PqenZxh6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.employee_residence= 'Pk'\n",
        "salary_record.employee_residence"
      ],
      "metadata": {
        "id": "iIBxRueWxo-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summaries**\n",
        "We can get the summaries of our data in the following ways:"
      ],
      "metadata": {
        "id": "qkDiv2Nt-DJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.salary.describe()"
      ],
      "metadata": {
        "id": "K2daH3EP-L5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method generates a high-level summary of the attributes of the given column. It is type-aware, meaning that its output changes based on the data type of the input. The output above only makes sense for numerical data; for string data here's what we get:"
      ],
      "metadata": {
        "id": "ozvT_OQj-gDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.job_title.describe()"
      ],
      "metadata": {
        "id": "sRZ6kCkt-hJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to get some particular simple summary statistic about a column in a DataFrame or a Series, there is usually a helpful pandas function that makes it happen.\n",
        "\n",
        "For example, to see the mean of the points allotted (e.g. what is the avg salary of a data scientist), we can use the mean() function:"
      ],
      "metadata": {
        "id": "tBPqyX1O-w8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.salary.mean()"
      ],
      "metadata": {
        "id": "SzKZ4Cql-yw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see a list of unique values we can use the unique() function:"
      ],
      "metadata": {
        "id": "G0fkCZZ2_chi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.job_title.unique()"
      ],
      "metadata": {
        "id": "UxLLUbbF_dmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see a list of unique values and how often they occur in the dataset, we can use the value_counts() method:"
      ],
      "metadata": {
        "id": "Bf48-gjI_mnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_record.job_title.value_counts()"
      ],
      "metadata": {
        "id": "nYuw546V_nS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}